{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_qHxrbexE4S",
        "outputId": "80f3e537-1b22-4984-d6eb-956c378c15e9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2024.1.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.7 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.7 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2024.1.3-py2.py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.4/87.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting appdirs>=1.4.0 (from pycuda)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.5)\n",
            "Building wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2024.1-cp310-cp310-linux_x86_64.whl size=661204 sha256=46eac7fa4324ce4bbfc54281ccf6248600bdfd3b8e984cfaa54d088f0f52504c\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/34/d2/9a349255a4eca3a486d82c79d21e138ce2ccd90f414d9d72b8\n",
            "Successfully built pycuda\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.3.5 pycuda-2024.1 pytools-2024.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU-IeGD-vxWZ",
        "outputId": "aaa10bc6-0769-4583-ed77-a6fa8eed9adf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_code = \"\"\"\n",
        "__global__ void normalize_image(float *img, int width, int height, float min_val, float max_val) {\n",
        "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    if (x < width && y < height) {\n",
        "        int idx = y * width + x;\n",
        "        img[idx] = (img[idx] - min_val) / (max_val - min_val);\n",
        "    }\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "LxgQDvMpxTn0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "\n",
        "# Compile the CUDA code\n",
        "mod = SourceModule(cuda_code)\n",
        "\n",
        "# Get the kernel function\n",
        "normalize_image = mod.get_function(\"normalize_image\")\n",
        "def normalize_image_gpu(images, min_val, max_val, batch_size=2, max_threads_per_block=512):\n",
        "    num_images, height, width, channels = images.shape\n",
        "    normalized_images = np.empty_like(images, dtype=np.float32)\n",
        "\n",
        "    for i in range(0, num_images, batch_size):\n",
        "        batch_images = images[i:i + batch_size].astype(np.float32).reshape(-1)\n",
        "        # Allocate pinned memory\n",
        "        batch_images_pinned = cuda.pagelocked_empty_like(batch_images)\n",
        "        np.copyto(batch_images_pinned, batch_images)\n",
        "\n",
        "        d_img = cuda.mem_alloc(batch_images_pinned.nbytes)\n",
        "        cuda.memcpy_htod(d_img, batch_images_pinned)\n",
        "\n",
        "        # Set hard bounds on the number of threads per block\n",
        "        block_x = min(max_threads_per_block, width)\n",
        "        block_y = min(max_threads_per_block // block_x, height)\n",
        "        block_size = (block_x, block_y, 1)\n",
        "\n",
        "        grid_x = (width + block_size[0] - 1) // block_size[0]\n",
        "        grid_y = (height + block_size[1] - 1) // block_size[1]\n",
        "        grid_size = (grid_x, grid_y, 1)\n",
        "\n",
        "        normalize_image(d_img, np.int32(width), np.int32(height), np.float32(min_val), np.float32(max_val), block=block_size, grid=grid_size)\n",
        "\n",
        "        cuda.memcpy_dtoh(batch_images_pinned, d_img)\n",
        "        d_img.free()\n",
        "\n",
        "        normalized_images[i:i + batch_size] = batch_images_pinned.reshape(-1, height, width, channels)\n",
        "\n",
        "    return normalized_images\n",
        "\n",
        "\n",
        "\n",
        "# # Example usage\n",
        "# images = np.random.rand(10, 128, 128, 3).astype(np.float32)\n",
        "# min_val, max_val = 0.0, 1.0\n",
        "# normalized_images = normalize_image_gpu(images, min_val, max_val)\n"
      ],
      "metadata": {
        "id": "yMip2Urgxmn1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4tDFjxJEvBJF"
      },
      "outputs": [],
      "source": [
        "# Write the CUDA code to a file (this one is for computing)\n",
        "cuda_code = \"\"\"\n",
        "__global__ void relu_forward(float* input, float* output, int size) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (idx < size) {\n",
        "        output[idx] = max(0.0f, input[idx]);\n",
        "    }\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "\n",
        "# Compile the CUDA code\n",
        "mod = SourceModule(cuda_code)\n",
        "\n",
        "# Get the kernel function\n",
        "relu_layer = mod.get_function(\"relu_forward\")\n",
        "\n",
        "def custom_relu(input_data):\n",
        "    size = input_data.size\n",
        "    output_data = np.empty_like(input_data, dtype=np.float32)\n",
        "\n",
        "    d_input = cuda.mem_alloc(input_data.nbytes)\n",
        "    d_output = cuda.mem_alloc(output_data.nbytes)\n",
        "\n",
        "    cuda.memcpy_htod(d_input, input_data)\n",
        "\n",
        "    block_size = 256\n",
        "    num_blocks = (size + block_size - 1) // block_size\n",
        "\n",
        "    relu_layer(d_input, d_output, np.int32(size), block=(block_size, 1, 1), grid=(num_blocks, 1))\n",
        "\n",
        "    cuda.memcpy_dtoh(output_data, d_output)\n",
        "    d_input.free()\n",
        "    d_output.free()\n",
        "\n",
        "    return output_data\n",
        "\n",
        "# Example usage\n",
        "# input_data = np.random.rand(1000).astype(np.float32)\n",
        "# output_data = custom_relu(input_data)\n",
        "# print(output_data)\n"
      ],
      "metadata": {
        "id": "hmTYumnBxCVG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the driver image list\n",
        "df = pd.read_csv('/content/drive/My Drive/Acads/MEngAI/CS 239/Datasets/Distracted Driving/driver_imgs_list.csv')\n",
        "df['img'] = df.apply(lambda row: os.path.join('/content/drive/My Drive/Acads/MEngAI/CS 239/Datasets/Distracted Driving/imgs/train', row['classname'], row['img']), axis=1)\n",
        "\n",
        "# Load and preprocess images\n",
        "file_paths = df['img'].values\n",
        "labels = pd.get_dummies(df['classname']).values\n",
        "\n",
        "# Convert file paths and labels to a TensorFlow dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
        "\n",
        "def load_and_preprocess_image_with_label(path, label):\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    image = image / 255.0\n",
        "    return image, label\n",
        "\n",
        "# Map the function to the dataset\n",
        "dataset = dataset.map(load_and_preprocess_image_with_label, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# Determine the number of samples in the dataset\n",
        "dataset_size = len(file_paths)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "val_size = dataset_size - train_size\n",
        "\n",
        "# Split the dataset\n",
        "train_dataset = dataset.take(train_size)\n",
        "val_dataset = dataset.skip(train_size)\n",
        "\n",
        "# Verify the sizes of the datasets\n",
        "train_count = sum(1 for _ in train_dataset)\n",
        "val_count = sum(1 for _ in val_dataset)\n",
        "\n",
        "print(f\"Train dataset size: {train_count}\")\n",
        "print(f\"Validation dataset size: {val_count}\")\n",
        "\n",
        "# Batch and prefetch the datasets\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "val_dataset = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# Load VGG16 model without top layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add custom layers\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(len(np.unique(df['classname'])), activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=10\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQamCg2Uxz4Q",
        "outputId": "485fc833-6bde-4770-8aa9-0f09bc5d7295"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 17939\n",
            "Validation dataset size: 4485\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               6422784   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21140042 (80.64 MB)\n",
            "Trainable params: 6425354 (24.51 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "561/561 [==============================] - 132s 233ms/step - loss: 3.5616 - accuracy: 0.0391 - val_loss: 2.3024 - val_accuracy: 0.1017\n",
            "Epoch 2/10\n",
            "561/561 [==============================] - 129s 229ms/step - loss: 2.3033 - accuracy: 0.1133 - val_loss: 2.3024 - val_accuracy: 0.1017\n",
            "Epoch 3/10\n",
            "561/561 [==============================] - 130s 232ms/step - loss: 2.3023 - accuracy: 0.1133 - val_loss: 2.3025 - val_accuracy: 0.1017\n",
            "Epoch 4/10\n",
            "561/561 [==============================] - 130s 232ms/step - loss: 2.3018 - accuracy: 0.1133 - val_loss: 2.3027 - val_accuracy: 0.1017\n",
            "Epoch 5/10\n",
            "561/561 [==============================] - 130s 232ms/step - loss: 2.3014 - accuracy: 0.1133 - val_loss: 2.3029 - val_accuracy: 0.1017\n",
            "Epoch 6/10\n",
            "561/561 [==============================] - 130s 231ms/step - loss: 2.3012 - accuracy: 0.1133 - val_loss: 2.3031 - val_accuracy: 0.1017\n",
            "Epoch 7/10\n",
            "561/561 [==============================] - 130s 232ms/step - loss: 2.3011 - accuracy: 0.1133 - val_loss: 2.3033 - val_accuracy: 0.1017\n",
            "Epoch 8/10\n",
            "561/561 [==============================] - 130s 232ms/step - loss: 2.3009 - accuracy: 0.1133 - val_loss: 2.3035 - val_accuracy: 0.1017\n",
            "Epoch 9/10\n",
            "561/561 [==============================] - 130s 232ms/step - loss: 2.3009 - accuracy: 0.1133 - val_loss: 2.3037 - val_accuracy: 0.1017\n",
            "Epoch 10/10\n",
            "561/561 [==============================] - 130s 232ms/step - loss: 2.3008 - accuracy: 0.1133 - val_loss: 2.3038 - val_accuracy: 0.1017\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the driver image list\n",
        "df = pd.read_csv('/content/drive/My Drive/Acads/MEngAI/CS 239/Datasets/Distracted Driving/driver_imgs_list.csv')\n",
        "df['img'] = df.apply(lambda row: os.path.join('/content/drive/My Drive/Acads/MEngAI/CS 239/Datasets/Distracted Driving/imgs/train', row['classname'], row['img']), axis=1)\n",
        "\n",
        "# Load and preprocess images\n",
        "file_paths = df['img'].values\n",
        "labels = pd.get_dummies(df['classname']).values\n",
        "\n",
        "# Convert file paths and labels to a TensorFlow dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
        "\n",
        "def load_and_preprocess_image_with_label(path, label):\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)  # Normalize to [0, 1]\n",
        "    return image, label\n",
        "\n",
        "def augment(image, label):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.2)\n",
        "    image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n",
        "    image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n",
        "    image = tf.image.random_hue(image, max_delta=0.2)\n",
        "    return image, label\n",
        "\n",
        "# Map the functions to the dataset\n",
        "dataset = dataset.map(load_and_preprocess_image_with_label, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# Determine the number of samples in the dataset\n",
        "dataset_size = len(file_paths)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "val_size = dataset_size - train_size\n",
        "\n",
        "# Split the dataset\n",
        "train_dataset = dataset.take(train_size).map(augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "val_dataset = dataset.skip(train_size)\n",
        "\n",
        "# Verify the sizes of the datasets\n",
        "train_count = sum(1 for _ in train_dataset)\n",
        "val_count = sum(1 for _ in val_dataset)\n",
        "\n",
        "print(f\"Train dataset size: {train_count}\")\n",
        "print(f\"Validation dataset size: {val_count}\")\n",
        "\n",
        "# Batch and prefetch the datasets\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "val_dataset = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# Load VGG16 model without top layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add custom layers\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(len(np.unique(df['classname'])), activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Learning rate scheduler\n",
        "def lr_schedule(epoch):\n",
        "    if epoch < 5:\n",
        "        return 1e-3\n",
        "    elif epoch < 10:\n",
        "        return 1e-4\n",
        "    else:\n",
        "        return 1e-5\n",
        "\n",
        "lr_callback = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=15,\n",
        "    callbacks=[lr_callback]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeSPOKDC4mSm",
        "outputId": "11cd7ec5-4e7a-49de-ba79-efbc39f37ea2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 17939\n",
            "Validation dataset size: 4485\n",
            "Epoch 1/15\n",
            "561/561 [==============================] - 120s 211ms/step - loss: 15.0570 - accuracy: 0.0473 - val_loss: 2.3023 - val_accuracy: 0.1017 - lr: 0.0010\n",
            "Epoch 2/15\n",
            "561/561 [==============================] - 130s 231ms/step - loss: 2.6733 - accuracy: 0.1117 - val_loss: 2.3024 - val_accuracy: 0.1017 - lr: 0.0010\n",
            "Epoch 3/15\n",
            "561/561 [==============================] - 131s 233ms/step - loss: 2.3318 - accuracy: 0.1134 - val_loss: 2.3026 - val_accuracy: 0.1017 - lr: 0.0010\n",
            "Epoch 4/15\n",
            "561/561 [==============================] - 132s 235ms/step - loss: 2.3060 - accuracy: 0.1142 - val_loss: 2.3028 - val_accuracy: 0.1017 - lr: 0.0010\n",
            "Epoch 5/15\n",
            "561/561 [==============================] - 131s 234ms/step - loss: 2.3058 - accuracy: 0.1141 - val_loss: 2.3032 - val_accuracy: 0.1017 - lr: 0.0010\n",
            "Epoch 6/15\n",
            "561/561 [==============================] - 131s 234ms/step - loss: 2.2998 - accuracy: 0.1142 - val_loss: 2.3033 - val_accuracy: 0.1017 - lr: 1.0000e-04\n",
            "Epoch 7/15\n",
            "561/561 [==============================] - 131s 233ms/step - loss: 2.2974 - accuracy: 0.1143 - val_loss: 2.3033 - val_accuracy: 0.1017 - lr: 1.0000e-04\n",
            "Epoch 8/15\n",
            "561/561 [==============================] - 132s 235ms/step - loss: 2.2968 - accuracy: 0.1147 - val_loss: 2.3033 - val_accuracy: 0.1017 - lr: 1.0000e-04\n",
            "Epoch 9/15\n",
            "561/561 [==============================] - 131s 234ms/step - loss: 2.2968 - accuracy: 0.1149 - val_loss: 2.3033 - val_accuracy: 0.1017 - lr: 1.0000e-04\n",
            "Epoch 10/15\n",
            "561/561 [==============================] - 131s 234ms/step - loss: 2.3020 - accuracy: 0.1156 - val_loss: 2.3034 - val_accuracy: 0.1017 - lr: 1.0000e-04\n",
            "Epoch 11/15\n",
            "561/561 [==============================] - 131s 233ms/step - loss: 2.3039 - accuracy: 0.1151 - val_loss: 2.3034 - val_accuracy: 0.1017 - lr: 1.0000e-05\n",
            "Epoch 12/15\n",
            "561/561 [==============================] - 132s 236ms/step - loss: 2.2962 - accuracy: 0.1150 - val_loss: 2.3034 - val_accuracy: 0.1017 - lr: 1.0000e-05\n",
            "Epoch 13/15\n",
            "561/561 [==============================] - 131s 234ms/step - loss: 2.2975 - accuracy: 0.1147 - val_loss: 2.3034 - val_accuracy: 0.1017 - lr: 1.0000e-05\n",
            "Epoch 14/15\n",
            "561/561 [==============================] - 131s 234ms/step - loss: 2.2955 - accuracy: 0.1153 - val_loss: 2.3034 - val_accuracy: 0.1017 - lr: 1.0000e-05\n",
            "Epoch 15/15\n",
            "561/561 [==============================] - 131s 233ms/step - loss: 2.2976 - accuracy: 0.1148 - val_loss: 2.3034 - val_accuracy: 0.1017 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Load the driver image list\n",
        "df = pd.read_csv('/content/drive/My Drive/Acads/MEngAI/CS 239/Datasets/Distracted Driving/driver_imgs_list.csv')\n",
        "\n",
        "# Assuming full body images are in a directory\n",
        "df['img'] = df.apply(lambda row: os.path.join('/content/drive/My Drive/Acads/MEngAI/CS 239/Datasets/Distracted Driving/imgs/train', row['classname'], row['img']), axis=1)\n",
        "\n",
        "# Remove rows with missing files\n",
        "df = df[df['img'].apply(os.path.exists)]\n",
        "\n",
        "# Load and preprocess images\n",
        "file_paths = df['img'].values\n",
        "labels = pd.get_dummies(df['classname']).values\n",
        "\n",
        "# Convert file paths and labels to a TensorFlow dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)  # Normalize to [0, 1]\n",
        "    return image\n",
        "\n",
        "def load_and_preprocess_image_with_label(path, label):\n",
        "    image = load_and_preprocess_image(path)\n",
        "    return image, label\n",
        "\n",
        "def augment(image, label):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.3)\n",
        "    image = tf.image.random_contrast(image, lower=0.7, upper=1.3)\n",
        "    image = tf.image.random_saturation(image, lower=0.7, upper=1.3)\n",
        "    image = tf.image.random_hue(image, max_delta=0.3)\n",
        "    return image, label\n",
        "\n",
        "# Map the functions to the dataset\n",
        "dataset = dataset.map(load_and_preprocess_image_with_label, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# Determine the number of samples in the dataset\n",
        "dataset_size = len(file_paths)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "val_size = dataset_size - train_size\n",
        "\n",
        "# Split the dataset\n",
        "train_dataset = dataset.take(train_size).map(lambda x, y: augment(x, y), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "val_dataset = dataset.skip(train_size)\n",
        "\n",
        "# Batch and prefetch the datasets\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "val_dataset = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# Load VGG19 model without top layers\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add custom layers with L2 regularization\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(len(np.unique(df['classname'])), activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Learning rate scheduler\n",
        "def lr_schedule(epoch):\n",
        "    if epoch < 5:\n",
        "        return 1e-3\n",
        "    elif epoch < 10:\n",
        "        return 1e-4\n",
        "    else:\n",
        "        return 1e-5\n",
        "\n",
        "lr_callback = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Model checkpoint\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n",
        "\n",
        "# Train the model with the callbacks\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=50,  # Increase the number of epochs\n",
        "    callbacks=[lr_callback, early_stopping, model_checkpoint]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8U5iAoJHyHm",
        "outputId": "32718f64-9589-4ca6-ed14-6e8ec81faa27"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 4s 0us/step\n",
            "Epoch 1/50\n",
            "561/561 [==============================] - ETA: 0s - loss: 29.1902 - accuracy: 0.0542"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r561/561 [==============================] - 152s 267ms/step - loss: 29.1902 - accuracy: 0.0542 - val_loss: 12.9529 - val_accuracy: 0.1017 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "561/561 [==============================] - 159s 282ms/step - loss: 11.2532 - accuracy: 0.0632 - val_loss: 8.7835 - val_accuracy: 0.0932 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "561/561 [==============================] - 158s 281ms/step - loss: 7.5536 - accuracy: 0.1159 - val_loss: 6.3659 - val_accuracy: 0.1017 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "561/561 [==============================] - 158s 280ms/step - loss: 5.8966 - accuracy: 0.1275 - val_loss: 5.1039 - val_accuracy: 0.1017 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "561/561 [==============================] - 157s 280ms/step - loss: 5.0047 - accuracy: 0.1323 - val_loss: 6.2416 - val_accuracy: 0.0932 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "561/561 [==============================] - 158s 281ms/step - loss: 4.6255 - accuracy: 0.1143 - val_loss: 4.4288 - val_accuracy: 0.1017 - lr: 1.0000e-04\n",
            "Epoch 7/50\n",
            "561/561 [==============================] - 158s 280ms/step - loss: 4.3090 - accuracy: 0.1157 - val_loss: 4.1997 - val_accuracy: 0.1017 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "561/561 [==============================] - 158s 281ms/step - loss: 4.1092 - accuracy: 0.1079 - val_loss: 4.0174 - val_accuracy: 0.1017 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "561/561 [==============================] - 158s 281ms/step - loss: 3.9248 - accuracy: 0.1131 - val_loss: 3.8381 - val_accuracy: 0.1017 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "561/561 [==============================] - 159s 283ms/step - loss: 3.7778 - accuracy: 0.1081 - val_loss: 3.6702 - val_accuracy: 0.1017 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "561/561 [==============================] - 157s 281ms/step - loss: 3.6558 - accuracy: 0.1136 - val_loss: 3.6476 - val_accuracy: 0.1017 - lr: 1.0000e-05\n",
            "Epoch 12/50\n",
            "561/561 [==============================] - 158s 281ms/step - loss: 3.6304 - accuracy: 0.1128 - val_loss: 3.6191 - val_accuracy: 0.1017 - lr: 1.0000e-05\n",
            "Epoch 13/50\n",
            "561/561 [==============================] - 156s 275ms/step - loss: 3.5996 - accuracy: 0.1109 - val_loss: 3.5837 - val_accuracy: 0.1017 - lr: 1.0000e-05\n",
            "Epoch 14/50\n",
            "561/561 [==============================] - 153s 271ms/step - loss: 3.5584 - accuracy: 0.1138 - val_loss: 3.5396 - val_accuracy: 0.1017 - lr: 1.0000e-05\n",
            "Epoch 15/50\n",
            "561/561 [==============================] - 158s 281ms/step - loss: 3.5063 - accuracy: 0.1182 - val_loss: 3.4837 - val_accuracy: 0.1023 - lr: 1.0000e-05\n",
            "Epoch 16/50\n",
            "561/561 [==============================] - 158s 282ms/step - loss: 3.4368 - accuracy: 0.1274 - val_loss: 3.4157 - val_accuracy: 0.1142 - lr: 1.0000e-05\n",
            "Epoch 17/50\n",
            "561/561 [==============================] - 157s 280ms/step - loss: 3.3391 - accuracy: 0.1396 - val_loss: 3.3310 - val_accuracy: 0.1565 - lr: 1.0000e-05\n",
            "Epoch 18/50\n",
            "561/561 [==============================] - 158s 281ms/step - loss: 3.2221 - accuracy: 0.1530 - val_loss: 3.2363 - val_accuracy: 0.1035 - lr: 1.0000e-05\n",
            "Epoch 19/50\n",
            "561/561 [==============================] - 158s 281ms/step - loss: 3.0781 - accuracy: 0.1759 - val_loss: 3.1395 - val_accuracy: 0.1282 - lr: 1.0000e-05\n",
            "Epoch 20/50\n",
            "561/561 [==============================] - 157s 279ms/step - loss: 2.8987 - accuracy: 0.2096 - val_loss: 3.0463 - val_accuracy: 0.2071 - lr: 1.0000e-05\n",
            "Epoch 21/50\n",
            "561/561 [==============================] - 158s 279ms/step - loss: 2.7163 - accuracy: 0.2398 - val_loss: 2.9185 - val_accuracy: 0.2537 - lr: 1.0000e-05\n",
            "Epoch 22/50\n",
            "561/561 [==============================] - 158s 280ms/step - loss: 2.5131 - accuracy: 0.2887 - val_loss: 2.8309 - val_accuracy: 0.2805 - lr: 1.0000e-05\n",
            "Epoch 23/50\n",
            "561/561 [==============================] - 157s 280ms/step - loss: 2.3262 - accuracy: 0.3310 - val_loss: 2.7313 - val_accuracy: 0.2992 - lr: 1.0000e-05\n",
            "Epoch 24/50\n",
            "561/561 [==============================] - 157s 279ms/step - loss: 2.1388 - accuracy: 0.4007 - val_loss: 2.5836 - val_accuracy: 0.3525 - lr: 1.0000e-05\n",
            "Epoch 25/50\n",
            "561/561 [==============================] - 158s 281ms/step - loss: 1.9316 - accuracy: 0.4698 - val_loss: 2.5594 - val_accuracy: 0.3639 - lr: 1.0000e-05\n",
            "Epoch 26/50\n",
            "561/561 [==============================] - 156s 278ms/step - loss: 1.7533 - accuracy: 0.5198 - val_loss: 2.5986 - val_accuracy: 0.3632 - lr: 1.0000e-05\n",
            "Epoch 27/50\n",
            "561/561 [==============================] - 155s 277ms/step - loss: 1.6166 - accuracy: 0.5564 - val_loss: 2.7137 - val_accuracy: 0.3574 - lr: 1.0000e-05\n",
            "Epoch 28/50\n",
            "561/561 [==============================] - 155s 276ms/step - loss: 1.5034 - accuracy: 0.5876 - val_loss: 2.6762 - val_accuracy: 0.3516 - lr: 1.0000e-05\n",
            "Epoch 29/50\n",
            "561/561 [==============================] - 155s 276ms/step - loss: 1.3965 - accuracy: 0.6239 - val_loss: 2.6548 - val_accuracy: 0.3581 - lr: 1.0000e-05\n",
            "Epoch 30/50\n",
            "561/561 [==============================] - 156s 278ms/step - loss: 1.2973 - accuracy: 0.6635 - val_loss: 2.5755 - val_accuracy: 0.3645 - lr: 1.0000e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Load the driver image list\n",
        "df = pd.read_csv('/content/drive/My Drive/Acads/MEngAI/CS 239/Datasets/Distracted Driving/driver_imgs_list.csv')\n",
        "\n",
        "# Assuming full body images are in a directory\n",
        "df['img'] = df.apply(lambda row: os.path.join('/content/drive/My Drive/Acads/MEngAI/CS 239/Datasets/Distracted Driving/imgs/train', row['classname'], row['img']), axis=1)\n",
        "\n",
        "# Remove rows with missing files\n",
        "df = df[df['img'].apply(os.path.exists)]\n",
        "\n",
        "# Load and preprocess images\n",
        "file_paths = df['img'].values\n",
        "labels = pd.get_dummies(df['classname']).values\n",
        "\n",
        "# Convert file paths and labels to a TensorFlow dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)  # Normalize to [0, 1]\n",
        "    return image\n",
        "\n",
        "def load_and_preprocess_image_with_label(path, label):\n",
        "    image = load_and_preprocess_image(path)\n",
        "    return image, label\n",
        "\n",
        "def augment(image, label):\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "    image = tf.image.random_flip_up_down(image)\n",
        "    image = tf.image.random_brightness(image, max_delta=0.3)\n",
        "    image = tf.image.random_contrast(image, lower=0.7, upper=1.3)\n",
        "    image = tf.image.random_saturation(image, lower=0.7, upper=1.3)\n",
        "    image = tf.image.random_hue(image, max_delta=0.3)\n",
        "    return image, label\n",
        "\n",
        "# Map the functions to the dataset\n",
        "dataset = dataset.map(load_and_preprocess_image_with_label, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# Determine the number of samples in the dataset\n",
        "dataset_size = len(file_paths)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "val_size = dataset_size - train_size\n",
        "\n",
        "# Split the dataset\n",
        "train_dataset = dataset.take(train_size).map(lambda x, y: augment(x, y), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "val_dataset = dataset.skip(train_size)\n",
        "\n",
        "# Batch and prefetch the datasets\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "val_dataset = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# Load EfficientNetB0 model without top layers\n",
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add custom layers with L2 regularization\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(len(np.unique(df['classname'])), activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Learning rate scheduler\n",
        "def lr_schedule(epoch):\n",
        "    if epoch < 5:\n",
        "        return 1e-3\n",
        "    elif epoch < 10:\n",
        "        return 1e-4\n",
        "    else:\n",
        "        return 1e-5\n",
        "\n",
        "lr_callback = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# Early stopping\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "# Model checkpoint\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss')\n",
        "\n",
        "# Train the model with the callbacks\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=50,  # Increase the number of epochs\n",
        "    callbacks=[lr_callback, early_stopping, model_checkpoint]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 948
        },
        "id": "68r87GB9GVrK",
        "outputId": "f172f178-d288-4fe0-c8d1-97972129568e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "561/561 [==============================] - ETA: 0s - loss: 15.2118 - accuracy: 0.1088"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r561/561 [==============================] - 99s 162ms/step - loss: 15.2118 - accuracy: 0.1088 - val_loss: 6.6018 - val_accuracy: 0.1017 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "561/561 [==============================] - 87s 154ms/step - loss: 5.5362 - accuracy: 0.1098 - val_loss: 4.4197 - val_accuracy: 0.1017 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "561/561 [==============================] - 87s 155ms/step - loss: 3.8546 - accuracy: 0.1138 - val_loss: 3.3411 - val_accuracy: 0.1017 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "561/561 [==============================] - 87s 155ms/step - loss: 3.0332 - accuracy: 0.1133 - val_loss: 2.7895 - val_accuracy: 0.1017 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "561/561 [==============================] - 87s 155ms/step - loss: 2.6375 - accuracy: 0.1133 - val_loss: 2.5204 - val_accuracy: 0.1017 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "561/561 [==============================] - 87s 155ms/step - loss: 2.5075 - accuracy: 0.1133 - val_loss: 2.5008 - val_accuracy: 0.1017 - lr: 1.0000e-04\n",
            "Epoch 7/50\n",
            "561/561 [==============================] - 86s 154ms/step - loss: 2.4861 - accuracy: 0.1133 - val_loss: 2.4778 - val_accuracy: 0.1017 - lr: 1.0000e-04\n",
            "Epoch 8/50\n",
            "561/561 [==============================] - 89s 157ms/step - loss: 2.4617 - accuracy: 0.1133 - val_loss: 2.4522 - val_accuracy: 0.1017 - lr: 1.0000e-04\n",
            "Epoch 9/50\n",
            "561/561 [==============================] - 88s 157ms/step - loss: 2.4352 - accuracy: 0.1133 - val_loss: 2.4251 - val_accuracy: 0.1017 - lr: 1.0000e-04\n",
            "Epoch 10/50\n",
            "561/561 [==============================] - 88s 157ms/step - loss: 2.4079 - accuracy: 0.1133 - val_loss: 2.3979 - val_accuracy: 0.1017 - lr: 1.0000e-04\n",
            "Epoch 11/50\n",
            "561/561 [==============================] - 88s 157ms/step - loss: 2.3926 - accuracy: 0.1133 - val_loss: 2.3949 - val_accuracy: 0.1017 - lr: 1.0000e-05\n",
            "Epoch 12/50\n",
            "561/561 [==============================] - 88s 157ms/step - loss: 2.3892 - accuracy: 0.1133 - val_loss: 2.3911 - val_accuracy: 0.1017 - lr: 1.0000e-05\n",
            "Epoch 13/50\n",
            "561/561 [==============================] - 88s 157ms/step - loss: 2.3850 - accuracy: 0.1133 - val_loss: 2.3864 - val_accuracy: 0.1017 - lr: 1.0000e-05\n",
            "Epoch 14/50\n",
            "530/561 [===========================>..] - ETA: 2s - loss: 2.3801 - accuracy: 0.1101"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-a57455bd726e>\u001b[0m in \u001b[0;36m<cell line: 110>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;31m# Train the model with the callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m    111\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1811\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1813\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1814\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1815\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    692\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mwrong\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m   \"\"\"\n\u001b[0;32m--> 631\u001b[0;31m   return nest_util.map_structure(\n\u001b[0m\u001b[1;32m    632\u001b[0m       \u001b[0mnest_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1064\u001b[0m   \"\"\"\n\u001b[1;32m   1065\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_core_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1067\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_data_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m   return _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1104\u001b[0m   return _tf_core_pack_sequence_as(\n\u001b[1;32m   1105\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \"\"\"\n\u001b[1;32m    393\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    358\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}