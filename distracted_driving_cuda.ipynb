{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_qHxrbexE4S",
        "outputId": "847433ba-f6ac-4f67-edbc-500b1ed2fe15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pycuda in /usr/local/lib/python3.10/dist-packages (2024.1)\n",
            "Requirement already satisfied: pytools>=2011.2 in /usr/local/lib/python3.10/dist-packages (from pycuda) (2024.1.3)\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: mako in /usr/local/lib/python3.10/dist-packages (from pycuda) (1.3.5)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU-IeGD-vxWZ",
        "outputId": "1b2574fa-5ebd-470e-9a44-ecba5a2d0efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_code = \"\"\"\n",
        "__global__ void normalize_image(float *img, int width, int height, float min_val, float max_val) {\n",
        "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    if (x < width && y < height) {\n",
        "        int idx = y * width + x;\n",
        "        img[idx] = (img[idx] - min_val) / (max_val - min_val);\n",
        "    }\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "LxgQDvMpxTn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "\n",
        "# Compile the CUDA code\n",
        "mod = SourceModule(cuda_code)\n",
        "\n",
        "# Get the kernel function\n",
        "normalize_image = mod.get_function(\"normalize_image\")\n",
        "def normalize_image_gpu(images, min_val, max_val, batch_size=8):\n",
        "    num_images, height, width, channels = images.shape\n",
        "    normalized_images = np.empty_like(images, dtype=np.float32)\n",
        "\n",
        "    for i in range(0, num_images, batch_size):\n",
        "        batch_images = images[i:i + batch_size].astype(np.float32).reshape(-1)\n",
        "        d_img = cuda.mem_alloc(batch_images.nbytes)\n",
        "        cuda.memcpy_htod(d_img, batch_images)\n",
        "\n",
        "        block_size = (16, 16, 1)\n",
        "        grid_size = ((width + block_size[0] - 1) // block_size[0], (height + block_size[1] - 1) // block_size[1], 1)\n",
        "\n",
        "        normalize_image(d_img, np.int32(width), np.int32(height), np.float32(min_val), np.float32(max_val), block=block_size, grid=grid_size)\n",
        "\n",
        "        cuda.memcpy_dtoh(batch_images, d_img)\n",
        "        d_img.free()\n",
        "\n",
        "        normalized_images[i:i + batch_size] = batch_images.reshape(-1, height, width, channels)\n",
        "\n",
        "    return normalized_images\n",
        "\n",
        "# Example usage\n",
        "images = np.random.rand(10, 128, 128, 3).astype(np.float32)\n",
        "min_val, max_val = 0.0, 1.0\n",
        "normalized_images = normalize_image_gpu(images, min_val, max_val)\n"
      ],
      "metadata": {
        "id": "yMip2Urgxmn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tDFjxJEvBJF"
      },
      "outputs": [],
      "source": [
        "# Write the CUDA code to a file (this one is for computing)\n",
        "cuda_code = \"\"\"\n",
        "__global__ void relu_forward(float* input, float* output, int size) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (idx < size) {\n",
        "        output[idx] = max(0.0f, input[idx]);\n",
        "    }\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "\n",
        "# Compile the CUDA code\n",
        "mod = SourceModule(cuda_code)\n",
        "\n",
        "# Get the kernel function\n",
        "relu_layer = mod.get_function(\"relu_forward\")\n",
        "\n",
        "def custom_relu(input_data):\n",
        "    size = input_data.size\n",
        "    output_data = np.empty_like(input_data, dtype=np.float32)\n",
        "\n",
        "    d_input = cuda.mem_alloc(input_data.nbytes)\n",
        "    d_output = cuda.mem_alloc(output_data.nbytes)\n",
        "\n",
        "    cuda.memcpy_htod(d_input, input_data)\n",
        "\n",
        "    block_size = 256\n",
        "    num_blocks = (size + block_size - 1) // block_size\n",
        "\n",
        "    relu_layer(d_input, d_output, np.int32(size), block=(block_size, 1, 1), grid=(num_blocks, 1))\n",
        "\n",
        "    cuda.memcpy_dtoh(output_data, d_output)\n",
        "    d_input.free()\n",
        "    d_output.free()\n",
        "\n",
        "    return output_data\n",
        "\n",
        "# Example usage\n",
        "input_data = np.random.rand(1000).astype(np.float32)\n",
        "output_data = custom_relu(input_data)\n",
        "print(output_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmTYumnBxCVG",
        "outputId": "3b24cf5a-bb32-41f7-dea0-0f869a1d855a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.18572665e-02 1.75320789e-01 9.96459007e-01 9.22944546e-01\n",
            " 8.03771198e-01 2.19261020e-01 9.89260972e-01 1.42660052e-01\n",
            " 2.81161755e-01 9.12258685e-01 2.87072301e-01 9.31347430e-01\n",
            " 4.05042320e-01 5.56055188e-01 6.60269678e-01 1.99712068e-02\n",
            " 2.97770590e-01 6.75668791e-02 9.53897178e-01 9.41719532e-01\n",
            " 2.53090858e-01 7.06065893e-01 3.46261442e-01 8.85691404e-01\n",
            " 1.58996522e-01 5.02579808e-01 3.56662780e-01 2.72213131e-01\n",
            " 5.19051850e-02 9.43120599e-01 3.92505467e-01 3.59832048e-01\n",
            " 1.38048932e-01 9.47691739e-01 6.01950526e-01 8.94782722e-01\n",
            " 6.10540986e-01 2.04158902e-01 7.44522393e-01 6.21400416e-01\n",
            " 8.58959854e-01 1.73515752e-01 1.82932645e-01 5.18565416e-01\n",
            " 3.16558450e-01 3.60562384e-01 5.69569111e-01 9.97245871e-03\n",
            " 7.32277870e-01 2.16897547e-01 2.72097737e-01 4.30449158e-01\n",
            " 5.26340663e-01 6.83251739e-01 1.69200718e-01 4.61802155e-01\n",
            " 2.83002645e-01 8.69428456e-01 3.99509119e-03 3.58003318e-01\n",
            " 4.10294712e-01 5.46375692e-01 5.55820279e-02 7.59413019e-02\n",
            " 2.83136815e-01 1.43487558e-01 9.83587503e-01 1.43858373e-01\n",
            " 1.99587315e-01 9.46473062e-01 2.58860532e-02 4.09696668e-01\n",
            " 7.04370022e-01 1.24517068e-01 7.06749082e-01 4.24904883e-01\n",
            " 9.71255302e-01 9.53583360e-01 6.09873950e-01 1.31549284e-01\n",
            " 7.17878997e-01 9.28911805e-01 9.12713230e-01 7.94736266e-01\n",
            " 3.28464627e-01 3.52047384e-01 2.06957310e-01 4.93249446e-01\n",
            " 1.54575706e-01 9.54611361e-01 1.20448709e-01 3.47057402e-01\n",
            " 9.44057226e-01 6.96144819e-01 4.09933358e-01 2.71212399e-01\n",
            " 5.80853522e-01 8.43669236e-01 3.83913219e-01 6.12506568e-01\n",
            " 7.01153517e-01 6.27784371e-01 5.31341076e-01 9.29344893e-01\n",
            " 9.52478498e-02 6.75809383e-01 5.07034361e-01 1.31608427e-01\n",
            " 6.98933423e-01 8.24551284e-02 4.11238372e-02 9.96870756e-01\n",
            " 1.98459357e-01 5.51797867e-01 7.45633543e-01 3.07457864e-01\n",
            " 6.10167861e-01 2.80411512e-01 9.09654677e-01 1.73697412e-01\n",
            " 7.94409513e-01 1.63140506e-01 2.60547251e-01 9.51249719e-01\n",
            " 8.45409930e-01 1.29684016e-01 1.17257617e-01 7.18790829e-01\n",
            " 3.21196020e-01 5.84293067e-01 6.06934607e-01 4.78304088e-01\n",
            " 3.14574867e-01 1.52131498e-01 9.40146804e-01 8.79782498e-01\n",
            " 7.95811355e-01 1.04769610e-01 1.56845242e-01 9.86546695e-01\n",
            " 7.94099346e-02 5.69507480e-01 7.96772599e-01 8.31859171e-01\n",
            " 8.77108753e-01 5.30023098e-01 9.09801900e-01 7.96152830e-01\n",
            " 6.99173927e-01 1.92437559e-01 6.20175898e-01 4.33181912e-01\n",
            " 8.30394983e-01 1.83210477e-01 5.88626921e-01 4.37559895e-02\n",
            " 2.99931526e-01 9.23895836e-01 7.77509809e-01 3.53769153e-01\n",
            " 8.68258059e-01 6.57472968e-01 8.23231161e-01 9.32476640e-01\n",
            " 3.36442620e-01 8.48384678e-01 2.07886562e-01 1.24951780e-01\n",
            " 3.44866008e-01 2.09938407e-01 3.04487854e-01 2.64004230e-01\n",
            " 2.33590662e-01 6.10075057e-01 2.78376848e-01 5.71813643e-01\n",
            " 3.02829623e-01 4.32240367e-01 4.35777277e-01 9.72704366e-02\n",
            " 1.08427487e-01 9.00891066e-01 6.54955348e-03 7.25407481e-01\n",
            " 8.75902116e-01 6.49453521e-01 8.79550457e-01 7.67047882e-01\n",
            " 6.68741405e-01 3.35107148e-01 6.23047985e-02 8.40301573e-01\n",
            " 7.05952883e-01 9.76572275e-01 5.54953456e-01 8.80348563e-01\n",
            " 6.75343931e-01 9.23900068e-01 1.13419719e-01 4.04997766e-01\n",
            " 3.30470055e-02 7.12103367e-01 6.53688490e-01 3.11099011e-02\n",
            " 2.74515927e-01 5.78047931e-01 6.80554211e-01 1.12317510e-01\n",
            " 4.89565641e-01 3.63516867e-01 9.44721103e-01 6.73760712e-01\n",
            " 1.30483285e-01 8.05326045e-01 9.25167143e-01 4.44941044e-01\n",
            " 6.94810212e-01 9.97510910e-01 4.68836688e-02 3.07219446e-01\n",
            " 2.59399176e-01 5.68725690e-02 7.03738809e-01 2.08481044e-01\n",
            " 6.36252940e-01 8.81380856e-01 8.60180914e-01 1.12481885e-01\n",
            " 9.47586298e-01 8.67543101e-01 9.27599519e-02 2.42030069e-01\n",
            " 1.94072142e-01 2.44264528e-01 1.87649488e-01 9.31963086e-01\n",
            " 3.90070260e-01 9.39123869e-01 6.16404295e-01 1.22147262e-01\n",
            " 8.95801261e-02 2.09673643e-01 4.50665563e-01 8.65635037e-01\n",
            " 3.98004502e-01 2.48057619e-01 6.42391562e-01 4.25300449e-01\n",
            " 4.17765975e-01 6.20347798e-01 7.28177905e-01 2.62923092e-01\n",
            " 4.79516715e-01 9.75322187e-01 9.86942887e-01 6.08171225e-01\n",
            " 8.29144120e-01 6.57967746e-01 2.44786069e-01 7.04454184e-01\n",
            " 8.71735215e-02 1.67690575e-01 4.72422212e-01 6.00833118e-01\n",
            " 3.56472880e-01 4.36795771e-01 4.59827214e-01 6.18025243e-01\n",
            " 2.13331059e-01 1.94604188e-01 9.55110729e-01 4.71085198e-02\n",
            " 5.49866140e-01 9.50270891e-01 2.26547554e-01 8.92844379e-01\n",
            " 2.96763211e-01 6.92234814e-01 9.76149380e-01 3.32565755e-01\n",
            " 6.48311138e-01 7.03975379e-01 4.00003195e-01 9.15958941e-01\n",
            " 5.60054779e-01 1.84372947e-01 1.30743772e-01 1.47271127e-01\n",
            " 3.44314367e-01 2.77521700e-01 4.83762957e-02 3.78554434e-01\n",
            " 6.33286536e-01 6.44561589e-01 4.16769862e-01 3.92226070e-01\n",
            " 3.21332604e-01 7.27539897e-01 7.45057523e-01 5.72053373e-01\n",
            " 6.89742789e-02 1.92811470e-02 7.49366522e-01 6.09915674e-01\n",
            " 5.57358503e-01 5.47536969e-01 5.36798298e-01 6.62484229e-01\n",
            " 3.98331434e-01 9.56967115e-01 9.46392298e-01 4.65785451e-02\n",
            " 8.55907053e-02 6.89361632e-01 2.12596342e-01 4.17428464e-01\n",
            " 5.90392888e-01 9.97919500e-01 4.23527479e-01 9.23190713e-01\n",
            " 6.03305161e-01 6.63130283e-01 7.46078134e-01 8.57715428e-01\n",
            " 6.45627320e-01 3.24549019e-01 8.73147026e-02 7.43993282e-01\n",
            " 4.95774209e-01 1.34087160e-01 6.07920252e-02 6.55027390e-01\n",
            " 4.05343652e-01 4.54601735e-01 3.05791885e-01 4.27808493e-01\n",
            " 8.24085057e-01 1.93691656e-01 5.27328551e-01 1.21423714e-01\n",
            " 3.16917509e-01 8.62200439e-01 4.46457595e-01 8.93077135e-01\n",
            " 1.58730999e-01 3.73263270e-01 4.72622156e-01 4.11654085e-01\n",
            " 3.45059368e-03 1.62411824e-01 1.66071087e-01 8.33810806e-01\n",
            " 6.07556343e-01 8.85070860e-01 4.94308025e-02 9.70410943e-01\n",
            " 2.25312456e-01 5.07488728e-01 8.02978456e-01 9.79573727e-01\n",
            " 5.62390566e-01 4.54604477e-02 5.05505562e-01 7.76773870e-01\n",
            " 5.22575736e-01 8.70394051e-01 4.74797368e-01 9.93676305e-01\n",
            " 3.36599439e-01 3.57766747e-01 6.39717758e-01 8.82400811e-01\n",
            " 2.91359536e-02 5.88799179e-01 6.04411364e-01 2.93432891e-01\n",
            " 5.92782855e-01 4.07003611e-01 9.93864954e-01 3.84224921e-01\n",
            " 4.90040898e-01 8.43980908e-01 7.73071349e-01 8.86603534e-01\n",
            " 5.92522264e-01 9.95558202e-01 7.70604014e-01 5.42587042e-01\n",
            " 1.55850425e-01 8.83447193e-03 9.56712604e-01 2.08274931e-01\n",
            " 3.14121127e-01 5.65235376e-01 1.27947614e-01 6.19484782e-01\n",
            " 3.31229001e-01 7.47975111e-01 8.62680852e-01 4.10157263e-01\n",
            " 2.80058712e-01 2.88786530e-01 1.81673598e-02 9.79017615e-01\n",
            " 7.15329707e-01 3.91829282e-01 3.02332878e-01 5.76254070e-01\n",
            " 6.34760320e-01 9.91176188e-01 1.46894857e-01 1.43655345e-01\n",
            " 9.53614712e-01 3.48858923e-01 5.77783346e-01 9.24786866e-01\n",
            " 5.32978028e-02 4.38379109e-01 4.02141362e-01 1.38501182e-01\n",
            " 4.83752131e-01 2.22094461e-01 8.71501625e-01 8.11624467e-01\n",
            " 6.17712677e-01 6.42586708e-01 1.27599776e-01 3.95736724e-01\n",
            " 3.99445564e-01 1.84721628e-03 8.32023323e-01 8.97519886e-01\n",
            " 7.00640619e-01 3.23634855e-02 1.40985087e-01 7.63079703e-01\n",
            " 7.80800939e-01 7.33664870e-01 1.12751946e-01 5.05521417e-01\n",
            " 4.30501670e-01 2.40968198e-01 5.28388858e-01 2.68386871e-01\n",
            " 1.96411327e-01 7.42062151e-01 9.77464736e-01 4.24156159e-01\n",
            " 5.85508883e-01 3.44660908e-01 5.01275539e-01 7.89362311e-01\n",
            " 7.88994372e-01 6.70124590e-02 1.79921970e-01 7.26542413e-01\n",
            " 8.45908105e-01 9.14099634e-01 6.55319870e-01 5.79727471e-01\n",
            " 8.87077808e-01 7.28784323e-01 5.54912612e-02 7.81794414e-02\n",
            " 5.40298104e-01 7.09320545e-01 9.74519789e-01 1.83410197e-01\n",
            " 8.22559595e-02 8.89670134e-01 7.43037879e-01 7.62560666e-01\n",
            " 6.40709400e-01 5.07587865e-02 9.81273890e-01 8.29902887e-01\n",
            " 1.43514335e-01 4.87155646e-01 6.19157441e-02 2.16641158e-01\n",
            " 4.84062046e-01 4.33164686e-01 1.37574807e-01 9.48325098e-01\n",
            " 2.36136630e-01 7.84677118e-02 3.30738574e-01 1.71744794e-01\n",
            " 9.92026746e-01 9.62650478e-01 2.25501269e-01 2.93328524e-01\n",
            " 4.14227962e-01 5.04776001e-01 6.51472986e-01 7.36858726e-01\n",
            " 2.57853806e-01 4.35507819e-02 1.16229504e-01 9.97112989e-01\n",
            " 2.92835772e-01 6.14428818e-01 3.75356078e-01 6.59437895e-01\n",
            " 3.92302305e-01 8.07453454e-01 2.83573896e-01 7.62224853e-01\n",
            " 8.70010972e-01 8.20795476e-01 4.32419896e-01 7.02642441e-01\n",
            " 9.41089690e-01 7.70743310e-01 3.51166606e-01 2.25872174e-01\n",
            " 7.85435557e-01 5.25304556e-01 9.13013965e-02 4.60269243e-01\n",
            " 2.66886085e-01 2.33782560e-01 3.86866897e-01 7.03920364e-01\n",
            " 6.52806759e-01 8.06081295e-01 4.48679090e-01 7.21369684e-01\n",
            " 9.97953594e-01 5.88170648e-01 5.56850553e-01 4.05826196e-02\n",
            " 9.67366338e-01 1.22417703e-01 9.47477520e-01 3.07028145e-01\n",
            " 2.21496344e-01 7.21125007e-01 5.57367742e-01 6.38841212e-01\n",
            " 2.64109254e-01 1.62107766e-01 8.15075159e-01 3.54327708e-01\n",
            " 6.88545227e-01 4.03944731e-01 7.98449039e-01 4.46041077e-01\n",
            " 8.25460076e-01 3.05606365e-01 3.89054030e-01 7.49407411e-01\n",
            " 7.84106255e-01 6.45705879e-01 5.18412054e-01 3.59559357e-02\n",
            " 1.11431353e-01 7.84436241e-02 5.05771220e-01 2.61344220e-02\n",
            " 6.96517944e-01 9.19984221e-01 1.29462019e-01 7.85781324e-01\n",
            " 3.89336795e-01 5.01317531e-02 6.43397391e-01 6.67378664e-01\n",
            " 3.82058531e-01 3.72030079e-01 2.73169637e-01 4.58593309e-01\n",
            " 3.13039757e-02 1.41332909e-01 3.67581993e-01 6.29402936e-01\n",
            " 3.34617078e-01 5.90283215e-01 5.86876154e-01 3.97398919e-01\n",
            " 7.59560585e-01 5.30746222e-01 5.70300043e-01 3.53618115e-01\n",
            " 8.00081372e-01 3.97324055e-01 4.11259800e-01 1.25583529e-01\n",
            " 8.53508040e-02 9.26712811e-01 5.56158721e-01 4.59630787e-01\n",
            " 9.95194167e-02 3.85030478e-01 4.70296472e-01 3.05502117e-01\n",
            " 5.10355592e-01 3.66740674e-01 7.35582888e-01 3.75982165e-01\n",
            " 6.35932803e-01 1.21629409e-01 7.31432796e-01 6.01404130e-01\n",
            " 7.38182008e-01 1.72096193e-02 8.20304573e-01 5.64258516e-01\n",
            " 3.33760649e-01 7.91711330e-01 5.09949803e-01 5.49836755e-01\n",
            " 2.50131395e-02 9.29856539e-01 6.79300904e-01 7.15172112e-01\n",
            " 5.83361208e-01 4.27330881e-01 9.35326338e-01 5.03024936e-01\n",
            " 9.90532458e-01 4.04977411e-01 1.91689238e-01 6.18943691e-01\n",
            " 8.69281232e-01 1.99060529e-01 6.87525034e-01 8.64760935e-01\n",
            " 5.19089937e-01 7.99917400e-01 1.21956974e-01 5.84886312e-01\n",
            " 6.37893826e-02 3.59570473e-01 6.13987327e-01 8.69858265e-02\n",
            " 7.57416606e-01 7.36084402e-01 1.98931932e-01 5.44681251e-01\n",
            " 2.92156637e-01 6.28230631e-01 9.78584170e-01 4.20442134e-01\n",
            " 1.34891197e-01 2.26574391e-01 6.88611209e-01 1.11378014e-01\n",
            " 7.04133570e-01 7.33215094e-01 3.14405024e-01 1.40605584e-01\n",
            " 2.10792258e-01 5.90593159e-01 3.64414006e-02 4.99104530e-01\n",
            " 1.04339451e-01 2.55833536e-01 2.51322776e-01 7.08488405e-01\n",
            " 5.70521951e-01 9.27020609e-01 1.57750219e-01 1.42278180e-01\n",
            " 3.22603285e-01 1.43641676e-03 5.23646414e-01 1.60002008e-01\n",
            " 7.06559241e-01 7.51977921e-01 3.42665702e-01 4.49238308e-02\n",
            " 8.60091090e-01 8.02629888e-02 9.04227018e-01 1.96479887e-01\n",
            " 1.48354933e-01 4.29489315e-01 9.32763040e-01 4.65415955e-01\n",
            " 1.59009427e-01 7.01958477e-01 2.46926561e-01 1.90002605e-01\n",
            " 5.86283207e-01 5.70322096e-01 8.74384642e-01 2.01946855e-01\n",
            " 7.35872447e-01 1.28763691e-01 4.40852940e-01 3.34923118e-01\n",
            " 8.62560987e-01 9.13068950e-01 2.52903283e-01 4.06465501e-01\n",
            " 6.55780435e-01 1.80418923e-01 4.62451398e-01 9.59355414e-01\n",
            " 2.68429667e-01 4.53805745e-01 6.26683652e-01 5.84556937e-01\n",
            " 6.63633287e-01 7.65562117e-01 8.15118477e-02 7.44660258e-01\n",
            " 9.26313639e-01 4.34441924e-01 2.56250590e-01 3.70708108e-01\n",
            " 7.78024316e-01 8.73364449e-01 7.56895781e-01 3.64805609e-01\n",
            " 4.70970720e-01 3.35750043e-01 3.43483031e-01 2.15613008e-01\n",
            " 4.45075393e-01 2.85302013e-01 2.76347965e-01 1.12394057e-01\n",
            " 5.36122322e-01 5.62029183e-01 2.32282564e-01 7.37617433e-01\n",
            " 8.38413358e-01 7.35100284e-02 5.26634097e-01 9.29242015e-01\n",
            " 4.72461939e-01 3.35576594e-01 9.58748162e-01 9.24436450e-01\n",
            " 6.23559475e-01 3.61471415e-01 1.94853812e-01 6.36305586e-02\n",
            " 4.19331372e-01 7.48456195e-02 3.52754056e-01 9.94873285e-01\n",
            " 4.41517204e-01 7.11787343e-01 3.25214028e-01 6.45369768e-01\n",
            " 7.13805914e-01 4.63002831e-01 9.89089668e-01 3.98202211e-01\n",
            " 7.24115133e-01 2.64639705e-01 6.77131593e-01 7.34737873e-01\n",
            " 5.12562618e-02 9.70619321e-01 3.78602117e-01 4.38681208e-02\n",
            " 5.62342286e-01 6.00606918e-01 5.04155517e-01 8.56739998e-01\n",
            " 2.75494725e-01 6.67078555e-01 8.65034521e-01 3.45964551e-01\n",
            " 9.49820101e-01 2.10385531e-01 2.96163112e-01 8.05743098e-01\n",
            " 4.10268635e-01 1.95079029e-01 5.52883565e-01 6.70096219e-01\n",
            " 3.22705984e-01 2.80522704e-01 4.79406774e-01 6.69917643e-01\n",
            " 7.45849013e-01 9.76315856e-01 8.92195821e-01 7.10296333e-01\n",
            " 6.58192456e-01 2.74872720e-01 9.77989137e-01 2.27451593e-01\n",
            " 7.69477785e-01 1.35523662e-01 1.65137738e-01 5.47130525e-01\n",
            " 8.30500901e-01 6.61279023e-01 5.58508396e-01 5.18812060e-01\n",
            " 3.21027964e-01 7.93258011e-01 9.95001018e-01 1.39100075e-01\n",
            " 9.25772637e-02 1.71539903e-01 2.53521889e-01 6.52526140e-01\n",
            " 6.77577138e-01 5.36789119e-01 3.44196081e-01 8.04130614e-01\n",
            " 7.16802359e-01 3.28325182e-01 4.62187856e-01 4.59418148e-01\n",
            " 8.69161487e-01 8.11484363e-03 3.85283947e-01 8.98550928e-01\n",
            " 5.70104659e-01 7.06476212e-01 5.41150093e-01 6.80777669e-01\n",
            " 9.87697840e-01 2.51760364e-01 7.51795411e-01 4.26638424e-01\n",
            " 9.69979584e-01 3.45773771e-02 5.40505052e-01 7.79961646e-01\n",
            " 3.20624530e-01 5.40203154e-01 7.16415167e-01 7.19817162e-01\n",
            " 6.59971595e-01 1.66366950e-01 2.47878507e-01 5.59907913e-01\n",
            " 4.77257185e-03 4.36688304e-01 5.00184903e-03 3.60439509e-01\n",
            " 1.79618895e-01 2.53242016e-01 2.10224211e-01 7.13822663e-01\n",
            " 5.53805649e-01 2.14156687e-01 4.72683728e-01 2.94124424e-01\n",
            " 4.77189571e-01 4.63778913e-01 7.15426862e-01 7.40142465e-01\n",
            " 2.81169564e-01 6.16991222e-01 6.07823730e-01 7.13255286e-01\n",
            " 2.61262864e-01 1.46403879e-01 3.99527311e-01 2.78463457e-02\n",
            " 5.80778718e-01 6.19226754e-01 5.93331993e-01 2.43630007e-01\n",
            " 9.51546669e-01 7.41274431e-02 2.42054328e-01 1.74078554e-01\n",
            " 2.97643870e-01 4.92961138e-01 7.18356729e-01 6.53097868e-01\n",
            " 7.90191352e-01 9.50033426e-01 1.41570359e-01 7.98396289e-01\n",
            " 8.00998986e-01 9.29806530e-02 1.14833303e-01 3.04814696e-01\n",
            " 6.85378850e-01 6.14316702e-01 3.33512574e-01 9.90068257e-01\n",
            " 2.47549281e-01 6.43675208e-01 6.31721497e-01 2.19016939e-01\n",
            " 4.55340356e-01 1.05946891e-01 3.91787797e-01 1.70698047e-01\n",
            " 1.40180066e-01 5.91646850e-01 9.71615553e-01 2.00702250e-01\n",
            " 6.92773104e-01 9.11518574e-01 4.92538124e-01 5.87739706e-01\n",
            " 9.21622813e-01 2.55941987e-01 6.00855052e-01 3.35123241e-01\n",
            " 6.66211069e-01 4.64474350e-01 3.83725822e-01 4.41469550e-01\n",
            " 6.92933857e-01 8.43066648e-02 9.27452147e-01 6.62448406e-02\n",
            " 8.57370138e-01 3.51525217e-01 2.70548016e-01 9.14855599e-01\n",
            " 1.39378577e-01 9.34952855e-01 5.49641922e-02 3.34199518e-01\n",
            " 1.15860172e-01 7.03768492e-01 7.33991981e-01 2.11972177e-01\n",
            " 7.09846139e-01 1.07024759e-01 7.00966954e-01 9.30777371e-01\n",
            " 7.42151976e-01 4.41429287e-01 8.26640427e-01 6.56983793e-01\n",
            " 7.45408416e-01 1.33019567e-01 7.63637125e-01 2.72729509e-02\n",
            " 4.01204258e-01 8.77455056e-01 7.87867308e-01 9.89024520e-01\n",
            " 1.75037757e-01 5.17078161e-01 1.32074535e-01 7.12488770e-01\n",
            " 9.32478487e-01 6.99513435e-01 3.39800894e-01 3.03969681e-02\n",
            " 1.56825483e-01 9.24856007e-01 9.45300832e-02 7.42284358e-01\n",
            " 5.16652822e-01 6.25231743e-01 8.08773756e-01 2.44642019e-01\n",
            " 2.51668990e-01 5.69171878e-03 8.54907036e-01 4.29543734e-01\n",
            " 6.63669646e-01 7.38026321e-01 8.61487687e-01 3.47695321e-01\n",
            " 3.77688020e-01 4.43323463e-01 3.95953268e-01 8.67233932e-01\n",
            " 2.56585002e-01 3.30601595e-02 6.21755458e-02 2.60930479e-01\n",
            " 9.98830140e-01 9.05653656e-01 7.63435662e-01 1.47853389e-01\n",
            " 8.46260011e-01 4.68613468e-02 7.77031422e-01 8.77781153e-01\n",
            " 2.17160240e-01 6.03345394e-01 8.12122524e-01 2.74484336e-01\n",
            " 5.59824798e-03 9.84639287e-01 2.45583892e-01 9.30172205e-01\n",
            " 3.76907557e-01 9.60950494e-01 3.63399565e-01 6.06307507e-01\n",
            " 1.69604376e-01 7.37057447e-01 4.58957642e-01 6.28511488e-01\n",
            " 8.38803360e-04 1.07453056e-02 2.67335773e-01 9.81706008e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input, Layer\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import concurrent.futures\n",
        "import numpy as np\n",
        "from tqdm import tqdm  # to show progress bar\n",
        "\n",
        "class CustomReLULayer(Layer):\n",
        "    def __init__(self):\n",
        "        super(CustomReLULayer, self).__init__()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_data = inputs.numpy().astype(np.float32)\n",
        "        output_data = custom_relu(input_data)\n",
        "        return tf.convert_to_tensor(output_data)\n",
        "\n",
        "\n",
        "# Load the driver image list\n",
        "df = pd.read_csv('/content/drive/My Drive/Acads/MEngAI/CS 239/Datasets/Distracted Driving/driver_imgs_list.csv')\n",
        "df['img'] = df.apply(lambda row: os.path.join('/content/drive/My Drive/Acads/MEngAI/CS 239/Datasets/Distracted Driving/imgs/train', row['classname'], row['img']), axis=1)\n",
        "\n",
        "# Load and preprocess images\n",
        "image_paths = df['img'].values\n",
        "labels = pd.get_dummies(df['classname']).values\n",
        "\n",
        "# Load images (this should be done with an efficient data loader)\n",
        "images = np.array([plt.imread(img_path) for img_path in tqdm(image_paths, desc=\"Processing images\")])\n",
        "\n",
        "\n",
        "# Normalize images using CUDA\n",
        "images = normalize_image_gpu(images, 0.0, 255.0)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load VGG16 model without top layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add custom layers\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = CustomReLULayer()(x)  # Use the custom CUDA-based ReLU layer\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(len(np.unique(df['classname'])), activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=10,\n",
        "    batch_size=64\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQamCg2Uxz4Q",
        "outputId": "cc4c206f-7766-4e1a-f3d3-08dd5636e52e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing images: 100%|██████████| 22424/22424 [01:50<00:00, 202.77it/s]\n"
          ]
        }
      ]
    }
  ]
}