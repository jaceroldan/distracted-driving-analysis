{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_qHxrbexE4S",
        "outputId": "80f3e537-1b22-4984-d6eb-956c378c15e9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2024.1.tar.gz (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.7 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.7 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2 (from pycuda)\n",
            "  Downloading pytools-2024.1.3-py2.py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.4/87.4 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting appdirs>=1.4.0 (from pycuda)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting mako (from pycuda)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pytools>=2011.2->pycuda) (4.12.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from mako->pycuda) (2.1.5)\n",
            "Building wheels for collected packages: pycuda\n",
            "  Building wheel for pycuda (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2024.1-cp310-cp310-linux_x86_64.whl size=661204 sha256=46eac7fa4324ce4bbfc54281ccf6248600bdfd3b8e984cfaa54d088f0f52504c\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/34/d2/9a349255a4eca3a486d82c79d21e138ce2ccd90f414d9d72b8\n",
            "Successfully built pycuda\n",
            "Installing collected packages: appdirs, pytools, mako, pycuda\n",
            "Successfully installed appdirs-1.4.4 mako-1.3.5 pycuda-2024.1 pytools-2024.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU-IeGD-vxWZ",
        "outputId": "aaa10bc6-0769-4583-ed77-a6fa8eed9adf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_code = \"\"\"\n",
        "__global__ void normalize_image(float *img, int width, int height, float min_val, float max_val) {\n",
        "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "\n",
        "    if (x < width && y < height) {\n",
        "        int idx = y * width + x;\n",
        "        img[idx] = (img[idx] - min_val) / (max_val - min_val);\n",
        "    }\n",
        "}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "LxgQDvMpxTn0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "\n",
        "# Compile the CUDA code\n",
        "mod = SourceModule(cuda_code)\n",
        "\n",
        "# Get the kernel function\n",
        "normalize_image = mod.get_function(\"normalize_image\")\n",
        "def normalize_image_gpu(images, min_val, max_val, batch_size=2, max_threads_per_block=512):\n",
        "    num_images, height, width, channels = images.shape\n",
        "    normalized_images = np.empty_like(images, dtype=np.float32)\n",
        "\n",
        "    for i in range(0, num_images, batch_size):\n",
        "        batch_images = images[i:i + batch_size].astype(np.float32).reshape(-1)\n",
        "        # Allocate pinned memory\n",
        "        batch_images_pinned = cuda.pagelocked_empty_like(batch_images)\n",
        "        np.copyto(batch_images_pinned, batch_images)\n",
        "\n",
        "        d_img = cuda.mem_alloc(batch_images_pinned.nbytes)\n",
        "        cuda.memcpy_htod(d_img, batch_images_pinned)\n",
        "\n",
        "        # Set hard bounds on the number of threads per block\n",
        "        block_x = min(max_threads_per_block, width)\n",
        "        block_y = min(max_threads_per_block // block_x, height)\n",
        "        block_size = (block_x, block_y, 1)\n",
        "\n",
        "        grid_x = (width + block_size[0] - 1) // block_size[0]\n",
        "        grid_y = (height + block_size[1] - 1) // block_size[1]\n",
        "        grid_size = (grid_x, grid_y, 1)\n",
        "\n",
        "        normalize_image(d_img, np.int32(width), np.int32(height), np.float32(min_val), np.float32(max_val), block=block_size, grid=grid_size)\n",
        "\n",
        "        cuda.memcpy_dtoh(batch_images_pinned, d_img)\n",
        "        d_img.free()\n",
        "\n",
        "        normalized_images[i:i + batch_size] = batch_images_pinned.reshape(-1, height, width, channels)\n",
        "\n",
        "    return normalized_images\n",
        "\n",
        "\n",
        "\n",
        "# # Example usage\n",
        "# images = np.random.rand(10, 128, 128, 3).astype(np.float32)\n",
        "# min_val, max_val = 0.0, 1.0\n",
        "# normalized_images = normalize_image_gpu(images, min_val, max_val)\n"
      ],
      "metadata": {
        "id": "yMip2Urgxmn1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4tDFjxJEvBJF"
      },
      "outputs": [],
      "source": [
        "# Write the CUDA code to a file (this one is for computing)\n",
        "cuda_code = \"\"\"\n",
        "__global__ void relu_forward(float* input, float* output, int size) {\n",
        "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (idx < size) {\n",
        "        output[idx] = max(0.0f, input[idx]);\n",
        "    }\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "import numpy as np\n",
        "\n",
        "# Compile the CUDA code\n",
        "mod = SourceModule(cuda_code)\n",
        "\n",
        "# Get the kernel function\n",
        "relu_layer = mod.get_function(\"relu_forward\")\n",
        "\n",
        "def custom_relu(input_data):\n",
        "    size = input_data.size\n",
        "    output_data = np.empty_like(input_data, dtype=np.float32)\n",
        "\n",
        "    d_input = cuda.mem_alloc(input_data.nbytes)\n",
        "    d_output = cuda.mem_alloc(output_data.nbytes)\n",
        "\n",
        "    cuda.memcpy_htod(d_input, input_data)\n",
        "\n",
        "    block_size = 256\n",
        "    num_blocks = (size + block_size - 1) // block_size\n",
        "\n",
        "    relu_layer(d_input, d_output, np.int32(size), block=(block_size, 1, 1), grid=(num_blocks, 1))\n",
        "\n",
        "    cuda.memcpy_dtoh(output_data, d_output)\n",
        "    d_input.free()\n",
        "    d_output.free()\n",
        "\n",
        "    return output_data\n",
        "\n",
        "# Example usage\n",
        "# input_data = np.random.rand(1000).astype(np.float32)\n",
        "# output_data = custom_relu(input_data)\n",
        "# print(output_data)\n"
      ],
      "metadata": {
        "id": "hmTYumnBxCVG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the driver image list\n",
        "df = pd.read_csv('/content/drive/My Drive/Acads/MEngAI/CS 239/Datasets/Distracted Driving/driver_imgs_list.csv')\n",
        "df['img'] = df.apply(lambda row: os.path.join('/content/drive/My Drive/Acads/MEngAI/CS 239/Datasets/Distracted Driving/imgs/train', row['classname'], row['img']), axis=1)\n",
        "\n",
        "# Load and preprocess images\n",
        "file_paths = df['img'].values\n",
        "labels = pd.get_dummies(df['classname']).values\n",
        "\n",
        "# Convert file paths and labels to a TensorFlow dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
        "\n",
        "def load_and_preprocess_image_with_label(path, label):\n",
        "    image = tf.io.read_file(path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [224, 224])\n",
        "    image = image / 255.0\n",
        "    return image, label\n",
        "\n",
        "# Map the function to the dataset\n",
        "dataset = dataset.map(load_and_preprocess_image_with_label, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# Determine the number of samples in the dataset\n",
        "dataset_size = len(file_paths)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "val_size = dataset_size - train_size\n",
        "\n",
        "# Split the dataset\n",
        "train_dataset = dataset.take(train_size)\n",
        "val_dataset = dataset.skip(train_size)\n",
        "\n",
        "# Verify the sizes of the datasets\n",
        "train_count = sum(1 for _ in train_dataset)\n",
        "val_count = sum(1 for _ in val_dataset)\n",
        "\n",
        "print(f\"Train dataset size: {train_count}\")\n",
        "print(f\"Validation dataset size: {val_count}\")\n",
        "\n",
        "# Batch and prefetch the datasets\n",
        "batch_size = 32\n",
        "\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "val_dataset = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# Load VGG16 model without top layers\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Add custom layers\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(len(np.unique(df['classname'])), activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=10\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQamCg2Uxz4Q",
        "outputId": "485fc833-6bde-4770-8aa9-0f09bc5d7295"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset size: 17939\n",
            "Validation dataset size: 4485\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               6422784   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 21140042 (80.64 MB)\n",
            "Trainable params: 6425354 (24.51 MB)\n",
            "Non-trainable params: 14714688 (56.13 MB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "561/561 [==============================] - 132s 233ms/step - loss: 3.5616 - accuracy: 0.0391 - val_loss: 2.3024 - val_accuracy: 0.1017\n",
            "Epoch 2/10\n",
            "561/561 [==============================] - 129s 229ms/step - loss: 2.3033 - accuracy: 0.1133 - val_loss: 2.3024 - val_accuracy: 0.1017\n",
            "Epoch 3/10\n",
            "561/561 [==============================] - 130s 232ms/step - loss: 2.3023 - accuracy: 0.1133 - val_loss: 2.3025 - val_accuracy: 0.1017\n",
            "Epoch 4/10\n",
            "561/561 [==============================] - 130s 232ms/step - loss: 2.3018 - accuracy: 0.1133 - val_loss: 2.3027 - val_accuracy: 0.1017\n",
            "Epoch 5/10\n",
            "561/561 [==============================] - 130s 232ms/step - loss: 2.3014 - accuracy: 0.1133 - val_loss: 2.3029 - val_accuracy: 0.1017\n",
            "Epoch 6/10\n",
            "561/561 [==============================] - 130s 231ms/step - loss: 2.3012 - accuracy: 0.1133 - val_loss: 2.3031 - val_accuracy: 0.1017\n",
            "Epoch 7/10\n",
            "561/561 [==============================] - 130s 232ms/step - loss: 2.3011 - accuracy: 0.1133 - val_loss: 2.3033 - val_accuracy: 0.1017\n",
            "Epoch 8/10\n",
            "561/561 [==============================] - 130s 232ms/step - loss: 2.3009 - accuracy: 0.1133 - val_loss: 2.3035 - val_accuracy: 0.1017\n",
            "Epoch 9/10\n",
            "561/561 [==============================] - 130s 232ms/step - loss: 2.3009 - accuracy: 0.1133 - val_loss: 2.3037 - val_accuracy: 0.1017\n",
            "Epoch 10/10\n",
            "561/561 [==============================] - 130s 232ms/step - loss: 2.3008 - accuracy: 0.1133 - val_loss: 2.3038 - val_accuracy: 0.1017\n"
          ]
        }
      ]
    }
  ]
}